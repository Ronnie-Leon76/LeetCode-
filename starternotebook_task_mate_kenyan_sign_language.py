# -*- coding: utf-8 -*-
"""StarterNotebook_Task_Mate_Kenyan_Sign_Language.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EdYbZiNIuuaKo4Qgcd4xDadweuUvpNew
"""

!pip install -q  fastai==1.0.61

# check version of fastai
import fastai

fastai.__version__

# connect to gdrive
from google.colab import drive
drive.mount("/content/gdrive")

import numpy as np 
import pandas as pd 

from fastai import *
from fastai.vision import *
from pathlib import Path
import matplotlib.pyplot as plt

import warnings
warnings.filterwarnings('ignore')

image_path = "/content/gdrive/MyDrive/Images"

"""### tfms helps to do data augmentation on the data to have a better pixel values"""

tfms=get_transforms(do_flip=True,flip_vert=True,max_lighting=0.3,max_zoom=1.8,max_warp=0.2,max_rotate=45)

"""### Read the data and pass the data augmentation function"""

df = pd.read_csv("/content/gdrive/MyDrive/Task_mate_new/Train.csv")

df.head()

# data = ImageDataBunch.from_df(path=image_path,df=df,ds_tfms=tfms,size=224,bs=64).torch()

data = ImageDataBunch.from_df(image_path,
                              df,
                              size=224,
                              valid_pct=0.20,
                              ds_tfms=tfms,
                              num_workers=2,
                              bs=8,
                             suffix='.jpg').normalize(imagenet_stats)



# There are 9 classes!
print(data.c)

# Look at some examples
data.show_batch(rows=3, figsize=(15, 15))

"""### Create a baseline model using resnet18"""

learn = cnn_learner(data, models.resnet18, metrics=[error_rate, accuracy])

# Fit
num_epochs = 3
learn.fit_one_cycle(num_epochs, 1e-4)

"""## predict on test set"""

test_df = pd.read_csv("/content/gdrive/MyDrive/Task_mate_new/Test.csv")

test_df.head()

test = ImageList.from_df(test_df, image_path, suffix='.jpg')

data.add_test(test)

predictions

preds_test,y_test = learn.get_preds(DatasetType.Test)

preds_test[:,i]

y_test

sub=pd.read_csv('/content/gdrive/MyDrive/Task_mate_new/Sample_Submission.csv')
k=[]
for col in sub.columns: 
  k.append(col) # creating list of the label

k

import os
submission = pd.DataFrame()
submission["ID"] = test_df["img_IDS"]
for i, c in enumerate(learn.data.classes):
  print(c)
  submission[c] = preds_test[:,i]
submission.head()

submission.to_csv('baseline_model.csv', index=False)

"""## Improving your Model Accuracy

* Perform more data augmentation
* Try other pre-trained model like (efficientnet model)
* Improve the epochs size
* Test Time Augmentations
"""